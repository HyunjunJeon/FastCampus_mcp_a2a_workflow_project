#!/usr/bin/env python3
"""Knowledge Agent - LangGraph ì§ì ‘ í˜¸ì¶œ ì˜ˆì œ.

Knowledge Agentë¥¼ ì§ì ‘ importí•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.
MCP Memory Serviceë¥¼ í™œìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì‹¤í–‰ ì „ì œ ì¡°ê±´:
- MCP Memory Serviceê°€ Dockerë¡œ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨
- ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ ì„ë² ë”© ëª¨ë¸ì´ í™œì„±í™”ë˜ì–´ ìˆì–´ì•¼ í•¨
"""

import asyncio
import json
import sys

from pathlib import Path


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# ê³µí†µ ëª¨ë“ˆ import
from examples.common.logging import (  # noqa: E402
    LogCapture,
    get_log_filename,
    get_result_filename,
)
from examples.common.server_checks import check_mcp_servers  # noqa: E402
from src.agents.knowledge.knowledge_agent_lg import (  # noqa: E402
    create_knowledge_agent,
    manage_knowledge,
)


def print_section(title: str) -> None:
    """ì„¹ì…˜ êµ¬ë¶„ì„  ì¶œë ¥."""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print('='*60)


async def test_store_memory():
    """ë©”ëª¨ë¦¬ ì €ì¥ í…ŒìŠ¤íŠ¸.

    íƒœê·¸ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ í¬í•¨í•œ ë©”ëª¨ë¦¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    """
    print("=" * 50)
    print("1. ë©”ëª¨ë¦¬ ì €ì¥ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # Knowledge Agent ìƒì„±
    agent = await create_knowledge_agent(is_debug=True)

    # ì‚¬ìš©ì ì •ë³´ ì €ì¥
    result = await manage_knowledge(
        agent=agent,
        operation="save",
        data={
            "name": "ê¹€ê°œë°œ",
            "role": "Python ê°œë°œì",
            "preferred_ide": "VS Code",
            "skills": ["Python", "FastAPI", "Docker", "LangGraph"],
            "project": "ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ"
        },
        context_id="test_store"
    )

    print("ì €ì¥ ê²°ê³¼:")
    print(f"- ìƒíƒœ: {result.get('workflow_status')}")
    print(f"- ì„±ê³µ: {result.get('success')}")

    if result.get('result'):
        print(f"- ì‘ë‹µ: {result['result'].get('response')[:200]}...")

    return result


async def test_semantic_search():
    """ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸.

    ë²¡í„° ì„ë² ë”©ì„ ì‚¬ìš©í•œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print("\n" + "=" * 50)
    print("2. ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # Knowledge Agent ìƒì„±
    agent = await create_knowledge_agent(is_debug=True)

    # Python ê°œë°œì ì •ë³´ ê²€ìƒ‰
    result = await manage_knowledge(
        agent=agent,
        operation="retrieve",
        query="ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ê°œë°œí•˜ëŠ” Python ê°œë°œìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?",
        context_id="test_semantic"
    )

    print("ê²€ìƒ‰ ê²°ê³¼:")
    print(f"- ìƒíƒœ: {result.get('workflow_status')}")
    print(f"- ì„±ê³µ: {result.get('success')}")

    if result.get('result'):
        response = result['result'].get('response', '')
        print("- ë°œê²¬ëœ ë©”ëª¨ë¦¬:")
        print(response[:500])

    return result


async def test_time_based_query():
    """ì‹œê°„ ê¸°ë°˜ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸.

    ìì—°ì–´ ì‹œê°„ í‘œí˜„ì„ ì‚¬ìš©í•œ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    print("\n" + "=" * 50)
    print("3. ì‹œê°„ ê¸°ë°˜ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # Knowledge Agent ìƒì„±
    agent = await create_knowledge_agent(is_debug=True)

    # ìµœê·¼ ì´ë²¤íŠ¸ ì €ì¥
    await manage_knowledge(
        agent=agent,
        operation="save",
        data="í”„ë¡œì íŠ¸ ë§ˆì¼ìŠ¤í†¤: create_react_agent íŒ¨í„´ì„ ì‚¬ìš©í•œ ì—ì´ì „íŠ¸ ë¦¬íŒ©í† ë§ ì™„ë£Œ",
        context_id="test_time_store"
    )

    # ìµœê·¼ ë©”ëª¨ë¦¬ ì¿¼ë¦¬
    result = await manage_knowledge(
        agent=agent,
        operation="retrieve",
        query="ì˜¤ëŠ˜ ì—ì´ì „íŠ¸ì™€ ê´€ë ¨í•´ì„œ ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆë‚˜ìš”?",
        context_id="test_time_query"
    )

    print("ì‹œê°„ ì¿¼ë¦¬ ê²°ê³¼:")
    print(f"- ìƒíƒœ: {result.get('workflow_status')}")
    print(f"- ì„±ê³µ: {result.get('success')}")

    if result.get('result'):
        print("- ìµœê·¼ ë©”ëª¨ë¦¬ ë°œê²¬ë¨")

    return result


async def test_tag_search():
    """íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸.

    íƒœê·¸ë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ì¡°ì§í™”ì™€ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print("\n" + "=" * 50)
    print("4. íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # Knowledge Agent ìƒì„±
    agent = await create_knowledge_agent(is_debug=True)

    # íŠ¹ì • íƒœê·¸ê°€ ìˆëŠ” ë©”ëª¨ë¦¬ë“¤ ì €ì¥
    memories_to_store = [
        {
            "content": "FastAPI ë°±ì—”ë“œ ì„œë²„ êµ¬ì„± ì™„ë£Œ",
            "tags": ["backend", "fastapi", "configuration"]
        },
        {
            "content": "ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œìš© Docker compose ì„¤ì •",
            "tags": ["docker", "deployment", "configuration"]
        },
        {
            "content": "LangGraph ì—ì´ì „íŠ¸ êµ¬í˜„ ê°€ì´ë“œë¼ì¸",
            "tags": ["langgraph", "agents", "documentation"]
        }
    ]

    for memory in memories_to_store:
        await manage_knowledge(
            agent=agent,
            operation="save",
            data=memory,
            context_id=f"test_tag_store_{memories_to_store.index(memory)}"
        )

    # íƒœê·¸ë¡œ ê²€ìƒ‰
    result = await manage_knowledge(
        agent=agent,
        operation="retrieve",
        query="êµ¬ì„±(configuration) ê´€ë ¨ëœ ëª¨ë“  ë©”ëª¨ë¦¬ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
        context_id="test_tag_search"
    )

    print("íƒœê·¸ ê²€ìƒ‰ ê²°ê³¼:")
    print(f"- ìƒíƒœ: {result.get('workflow_status')}")
    print(f"- ì„±ê³µ: {result.get('success')}")

    if result.get('result'):
        print("- êµ¬ì„± ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰ë¨")

    return result


async def test_complex_workflow():
    """ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸.

    ì €ì¥, ê²€ìƒ‰, ì—…ë°ì´íŠ¸, ê²€ì¦ì˜ ì „ì²´ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print("\n" + "=" * 50)
    print("5. ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # Knowledge Agent ìƒì„±
    agent = await create_knowledge_agent(is_debug=True)

    # ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°: í”„ë¡œì íŠ¸ ì •ë³´ ì €ì¥, ê²€ìƒ‰, ì—…ë°ì´íŠ¸, ê²€ì¦
    workflow_steps = [
        {
            "step": "í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜ ì €ì¥",
            "operation": "save",
            "data": {
                "project": "ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ",
                "architecture": {
                    "agents": ["Planner", "Knowledge", "Executor", "Browser"],
                    "pattern": "create_react_agent",
                    "mcp_tools": ["memory-service", "playwright", "notion", "codeinterpreter"]
                },
                "status": "ê°œë°œ ì¤‘"
            }
        },
        {
            "step": "ì•„í‚¤í…ì²˜ ì •ë³´ ê²€ìƒ‰",
            "operation": "retrieve",
            "query": "ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì—ëŠ” ì–´ë–¤ ì—ì´ì „íŠ¸ë“¤ì´ ìˆë‚˜ìš”?"
        },
        {
            "step": "í”„ë¡œì íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸",
            "operation": "update",
            "data": "í”„ë¡œì íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸: í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¡œ ë³€ê²½"
        },
        {
            "step": "ì—…ë°ì´íŠ¸ ê²€ì¦",
            "operation": "retrieve",
            "query": "í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        }
    ]

    for step in workflow_steps:
        print(f"\nì‹¤í–‰ ì¤‘: {step['step']}")

        if step['operation'] in ['save', 'update']:
            result = await manage_knowledge(
                agent=agent,
                operation=step['operation'],
                data=step['data'],
                context_id=f"workflow_{workflow_steps.index(step)}"
            )
        else:
            result = await manage_knowledge(
                agent=agent,
                operation=step['operation'],
                query=step.get('query'),
                context_id=f"workflow_{workflow_steps.index(step)}"
            )

        print(f"  ê²°ê³¼: {'ì„±ê³µ' if result.get('success') else 'ì‹¤íŒ¨'}")

    print("\nâœ… ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
    return result


async def main() -> None:
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    # ë¡œê·¸ ìº¡ì²˜ ì‹œì‘
    log_capture = LogCapture()
    log_capture.start_capture()

    try:
        print_section("Knowledge Agent - LangGraph ì˜ˆì œ")
        print("Knowledge Agentë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

        # 1. MCP ì„œë²„ ìƒíƒœ í™•ì¸ (ì„ íƒì‚¬í•­)
        print("\n[ì •ë³´] MCP ì„œë²„ ìƒíƒœ í™•ì¸...")
        await check_mcp_servers("knowledge")

        # 2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
        all_results = []

        # í…ŒìŠ¤íŠ¸ 1: ë©”ëª¨ë¦¬ ì €ì¥
        result1 = await test_store_memory()
        all_results.append(result1)

        # í…ŒìŠ¤íŠ¸ 2: ì‹œë§¨í‹± ê²€ìƒ‰
        # result2 = await test_semantic_search()
        # all_results.append(result2)

        # # í…ŒìŠ¤íŠ¸ 3: ì‹œê°„ ê¸°ë°˜ ì¿¼ë¦¬
        # result3 = await test_time_based_query()
        # all_results.append(result3)

        # # í…ŒìŠ¤íŠ¸ 4: íƒœê·¸ ê²€ìƒ‰
        # result4 = await test_tag_search()
        # all_results.append(result4)

        # í…ŒìŠ¤íŠ¸ 5: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°
        result5 = await test_complex_workflow()
        all_results.append(result5)

        # 3. ê²°ê³¼ ìš”ì•½
        print_section("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")

        successful_tests = sum(1 for r in all_results if r.get("success"))
        total_tests = len(all_results)

        print(f"âœ¨ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ : {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)")

        test_names = [
            "ë©”ëª¨ë¦¬ ì €ì¥",
            "ì‹œë§¨í‹± ê²€ìƒ‰",
            "ì‹œê°„ ê¸°ë°˜ ì¿¼ë¦¬",
            "íƒœê·¸ ê²€ìƒ‰",
            "ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°"
        ]

        for i, result in enumerate(all_results):
            status = "âœ…" if result.get("success") else "âŒ"
            print(f"{status} {test_names[i]}")

        # 4. ì „ì²´ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        output_dir = Path("../../logs/examples/langgraph")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / get_result_filename("knowledge_result")

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)

        print(f"\nì „ì²´ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        print_section("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print("\nğŸ§  Knowledge Agent í•µì‹¬ ê¸°ëŠ¥:")
        print("  - ë²¡í„° ì„ë² ë”©ì„ í†µí•œ ì‹œë§¨í‹± ê²€ìƒ‰")
        print("  - ìì—°ì–´ ì‹œê°„ ì¿¼ë¦¬ ì²˜ë¦¬")
        print("  - íƒœê·¸ ê¸°ë°˜ ì¡°ì§í™”")
        print("  - Docker MCP ì„œë¹„ìŠ¤ í†µí•©")
        print("  - ìë™ ì‘ì—… ê°ì§€")

    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e!s}")
        import traceback
        traceback.print_exc()

    finally:
        try:
            log_capture.stop_capture()
            log_dir = Path("../../logs/examples/langgraph")
            log_dir.mkdir(parents=True, exist_ok=True)
            log_filename = log_dir / get_log_filename("knowledge_langgraph_log")
            log_capture.save_log(str(log_filename))
            print(f"\nì‹¤í–‰ ë¡œê·¸ê°€ {log_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as log_error:
            print(f"\në¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {log_error}")


if __name__ == "__main__":
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(main())
